# UTM + Ubuntu + Alpine 集群配置指南

## 您的环境架构

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         Mac M3 (物理机)                                  │
│                            运行 UTM                                      │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                      Ubuntu 24.04 VM (宿主机)                            │
│                         运行 QEMU/KVM                                    │
│                                                                         │
│   ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                │
│   │   Alpine    │    │   Alpine    │    │   Alpine    │                │
│   │   Master    │    │   Slave1    │    │   Slave2    │                │
│   │  (嵌套VM)   │    │  (嵌套VM)   │    │  (嵌套VM)   │                │
│   └─────────────┘    └─────────────┘    └─────────────┘                │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 第一步：确认网络配置

### 1.1 查看 Alpine VM 的 IP 地址

在 Ubuntu 宿主机上执行：

```bash
# 查看虚拟机列表
virsh list --all

# 或者如果用 QEMU 直接启动，查看网络
ip addr show
```

在每台 Alpine VM 内执行：

```bash
# 查看 IP
ip addr show eth0
# 或
ifconfig
```

### 1.2 记录您的网络信息

请填写您的实际 IP（示例）：

| 节点          | IP 地址              | SSH 端口 | 角色                      |
| ------------- | -------------------- | -------- | ------------------------- |
| Ubuntu 宿主机 | 192.168.64.1 (假设)  | 22       | KVM Host + 注入控制中心   |
| Alpine Master | 192.168.64.10 (假设) | 22       | NameNode, ResourceManager |
| Alpine Slave1 | 192.168.64.11 (假设) | 22       | DataNode, NodeManager     |
| Alpine Slave2 | 192.168.64.12 (假设) | 22       | DataNode, NodeManager     |

---

## 第二步：部署文件位置

### 文件部署总览

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      Ubuntu 24.04 宿主机                                 │
│                                                                         │
│   ~/fault-injection/                                                    │
│   ├── kvm注入/                    ← 【部署在这里】                       │
│   │   ├── cpu-fi/                 ← 内核模块 (在 Ubuntu 上加载)          │
│   │   ├── memory-fi/                                                    │
│   │   ├── file-fi/                                                      │
│   │   ├── hadoop-fi/              ← Hadoop 注入 (控制 Alpine 集群)       │
│   │   ├── cloudstack-fi/          ← CloudStack 注入                     │
│   │   ├── cluster_controller.c    ← 统一控制器                          │
│   │   └── cluster.conf            ← 集群配置文件                         │
│   │                                                                     │
│   └── 虚拟机注入/                  ← 【部署在这里】                       │
│       ├── cpu_injector                                                  │
│       ├── network_injector                                              │
│       └── process_injector                                              │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
                    │
                    │ SSH 远程控制 / 网络注入
                    ▼
┌───────────────────────────────────────────────────────────────────────────┐
│                        Alpine Linux 虚拟机集群                              │
│                                                                           │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐            │
│  │  Alpine Master  │  │  Alpine Slave1  │  │  Alpine Slave2  │            │
│  │                 │  │                 │  │                 │            │
│  │  Hadoop:        │  │  Hadoop:        │  │  Hadoop:        │            │
│  │  - NameNode     │  │  - DataNode     │  │  - DataNode     │            │
│  │  - ResourceMgr  │  │  - NodeManager  │  │  - NodeManager  │            │
│  │                 │  │                 │  │                 │            │
│  │  [可选] 复制     │   │  [可选] 复制     │  │  [可选] 复制    │             │
│  │  虚拟机注入/      │  │  虚拟机注入/      │  │  虚拟机注入/    │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘            │
└───────────────────────────────────────────────────────────────────────────┘
```

---

## 第三步：在 Ubuntu 宿主机上配置

### 3.1 克隆代码

```bash
# SSH 到 Ubuntu 宿主机 (从 Mac 终端)
ssh your_user@<Ubuntu_IP>

# 创建工作目录
mkdir -p ~/fault-injection
cd ~/fault-injection

# 克隆代码并切换分支
git clone https://github.com/VENELE11/fault-injection.git .
git checkout copilot/enhance-fault-injection-code
```

### 3.2 安装编译依赖

```bash
# 更新包管理器
sudo apt update

# 安装编译工具
sudo apt install -y build-essential gcc make

# 安装内核头文件 (用于编译内核模块)
sudo apt install -y linux-headers-$(uname -r)

# 安装网络工具 (用于 tc/iptables 注入)
sudo apt install -y iproute2 iptables
```

### 3.3 编译所有工具

```bash
# 编译 kvm注入 目录
cd ~/fault-injection/kvm注入/
make all

# 编译 虚拟机注入 目录
cd ~/fault-injection/虚拟机注入/
make all
```

### 3.4 配置集群信息

编辑 `cluster.conf`：

```bash
cd ~/fault-injection/kvm注入/
nano cluster.conf
```

根据您的 Alpine VM IP 地址修改：

```conf
# 格式: 节点名,IP地址,SSH端口,角色
# 请将下面的 IP 替换为您实际的 Alpine VM IP

master,192.168.64.10,22,NameNode,ResourceManager
slave1,192.168.64.11,22,DataNode,NodeManager
slave2,192.168.64.12,22,DataNode,NodeManager
```

---

## 第四步：配置 Alpine VM

### 4.1 在每台 Alpine 上安装必要软件

SSH 到每台 Alpine VM 执行：

```bash
# 更新包管理器
apk update

# 安装基础工具
apk add openssh bash curl wget

# 安装 Java (Hadoop 需要)
apk add openjdk11

# 启动 SSH 服务
rc-update add sshd
service sshd start

# 设置 root 密码 (如果还没设置)
passwd root

# 允许 root SSH 登录 (测试环境)
echo "PermitRootLogin yes" >> /etc/ssh/sshd_config
service sshd restart
```

### 4.2 配置 SSH 免密登录

在 **Ubuntu 宿主机** 上执行：

```bash
# 生成 SSH 密钥 (如果没有)
ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa

# 复制公钥到每台 Alpine VM (替换为实际 IP)
ssh-copy-id root@192.168.64.10  # master
ssh-copy-id root@192.168.64.11  # slave1
ssh-copy-id root@192.168.64.12  # slave2

# 测试免密登录
ssh root@192.168.64.10 "hostname"
ssh root@192.168.64.11 "hostname"
ssh root@192.168.64.12 "hostname"
```

---

## 第五步：安装 Hadoop 集群 (在 Alpine 上)

### 5.1 下载并配置 Hadoop

在 **每台 Alpine VM** 上执行：

```bash
# 下载 Hadoop
cd /opt
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar -xzf hadoop-3.3.6.tar.gz
mv hadoop-3.3.6 hadoop

# 设置环境变量
cat >> /etc/profile << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
EOF

source /etc/profile
```

### 5.2 配置 Hadoop (Master 节点)

在 **Alpine Master** 上编辑配置文件：

```bash
cd /opt/hadoop/etc/hadoop

# 1. core-site.xml
cat > core-site.xml << 'EOF'
<?xml version="1.0"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://192.168.64.10:9000</value>
    </property>
</configuration>
EOF

# 2. hdfs-site.xml
cat > hdfs-site.xml << 'EOF'
<?xml version="1.0"?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop/data/datanode</value>
    </property>
</configuration>
EOF

# 3. workers 文件 (列出所有 DataNode)
cat > workers << 'EOF'
192.168.64.11
192.168.64.12
EOF

# 4. 创建数据目录
mkdir -p /opt/hadoop/data/namenode
```

### 5.3 配置 Slave 节点

在 **Alpine Slave1 和 Slave2** 上：

```bash
cd /opt/hadoop/etc/hadoop

# 复制 Master 的配置 (或手动创建相同的 core-site.xml 和 hdfs-site.xml)
# 创建数据目录
mkdir -p /opt/hadoop/data/datanode
```

### 5.4 启动 Hadoop

在 **Master 节点** 上：

```bash
# 首次启动需要格式化 NameNode
hdfs namenode -format

# 启动 HDFS
start-dfs.sh

# 启动 YARN
start-yarn.sh

# 检查进程
jps
# 应该看到: NameNode, SecondaryNameNode, ResourceManager
```

在 **Slave 节点** 上检查：

```bash
jps
# 应该看到: DataNode, NodeManager
```

---

## 第六步：测试故障注入

### 6.1 启动统一控制器

在 **Ubuntu 宿主机** 上：

```bash
cd ~/fault-injection/kvm注入/

# 启动控制器
sudo ./cluster_controller
```

您将看到菜单：

```
╔════════════════════════════════════════════════════════════╗
║          集群故障注入统一控制器 v1.0                          ║
║          (VM / Hadoop / CloudStack)                         ║
╠════════════════════════════════════════════════════════════╣
║  [1] 虚拟机故障注入      [2] Hadoop故障注入                   ║
║  [3] CloudStack故障注入  [4] 预设故障场景                     ║
║  [5] 查看集群状态        [6] 一键恢复所有                     ║
║  [7] 加载集群配置        [q] 退出                             ║
╚════════════════════════════════════════════════════════════╝
```

### 6.2 测试 Hadoop 注入

```bash
# 方法1: 通过控制器
sudo ./cluster_controller
# 选择 [2] Hadoop故障注入
# 选择 [11] 查看Hadoop进程状态

# 方法2: 直接使用 hadoop_injector
cd hadoop-fi/
./hadoop_injector list          # 查看进程
sudo ./hadoop_injector crash dn  # 杀死 DataNode
sudo ./hadoop_injector hang nn   # 挂起 NameNode
```

### 6.3 测试网络注入

```bash
cd ~/fault-injection/虚拟机注入/

# 对 Ubuntu 宿主机网络注入延迟
sudo ./network_injector 1 100ms

# 清理
sudo ./network_injector 0
```

### 6.4 测试内核模块 (高级)

```bash
cd ~/fault-injection/kvm注入/cpu-fi/

# 加载内核模块
sudo insmod cpu-reg.ko

# 检查是否加载成功
dmesg | tail
lsmod | grep cpu

# 卸载模块
sudo rmmod cpu_reg
```

---

## 快速参考卡片

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          快速参考                                        │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  【在 Ubuntu 宿主机执行】                                                │
│                                                                         │
│  启动控制器:     cd ~/fault-injection/kvm注入 && sudo ./cluster_controller│
│  查看 Hadoop:    ./hadoop-fi/hadoop_injector list                       │
│  杀 NameNode:    sudo ./hadoop-fi/hadoop_injector crash nn              │
│  杀 DataNode:    sudo ./hadoop-fi/hadoop_injector crash dn              │
│  网络隔离:       sudo ./hadoop-fi/hadoop_injector network 192.168.64.11 │
│  网络延迟:       sudo ./虚拟机注入/network_injector 1 100ms              │
│  清理网络:       sudo ./虚拟机注入/network_injector 0                    │
│                                                                         │
│  【在 Alpine Master 执行】                                               │
│                                                                         │
│  启动 Hadoop:    start-dfs.sh && start-yarn.sh                          │
│  停止 Hadoop:    stop-yarn.sh && stop-dfs.sh                            │
│  检查进程:       jps                                                    │
│  检查 HDFS:      hdfs dfsadmin -report                                  │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 常见问题

### Q1: SSH 连接 Alpine 失败

```bash
# 在 Alpine 上检查 SSH 服务
service sshd status

# 检查防火墙
iptables -L

# 确保允许 root 登录
grep PermitRootLogin /etc/ssh/sshd_config
```

### Q2: Hadoop 命令找不到

```bash
# 确保环境变量已加载
source /etc/profile
echo $HADOOP_HOME

# 或使用完整路径
/opt/hadoop/bin/hdfs dfsadmin -report
```

### Q3: 内核模块加载失败

```bash
# 检查内核版本匹配
uname -r
ls /lib/modules/

# 重新安装内核头文件
sudo apt install linux-headers-$(uname -r)

# 重新编译
cd ~/fault-injection/kvm注入/
make clean && make all
```

---

需要我详细解释某个步骤吗？或者您遇到了具体的配置问题？