# Hadoop é›†ç¾¤ç¯å¢ƒæ¢å¤ä¸å¯åŠ¨æ‰‹å†Œ

## 1. å®¿ä¸»æœºï¼šå¯åŠ¨è™šæ‹Ÿæœºè„šæœ¬

åœ¨ **Ubuntu å®¿ä¸»æœº**ä¸Šï¼Œä½¿ç”¨æ”¯æŒâ€œåŒç½‘å¡â€çš„è„šæœ¬å¯åŠ¨è™šæ‹Ÿæœºã€‚ç½‘å¡ 1 ç”¨äº SSH è¿æ¥ï¼Œç½‘å¡ 2 ç”¨äºé›†ç¾¤å†…ç½‘é€šä¿¡ã€‚

Bash

```
#!/bin/bash
# ä¿å­˜ä¸º run_cluster.sh

if [ -z "$1" ]; then
    echo "ç”¨æ³•: ./run_cluster.sh <master|slave1|slave2>"
    exit 1
fi

NODE=$1

# é…ç½®ï¼šæ ¹æ®èŠ‚ç‚¹ååˆ†é… SSH ç«¯å£è½¬å‘å’Œå†…ç½‘ MAC åç¼€
if [ "$NODE" == "master" ]; then
    SUFFIX="10"
    HOST_PORT="2220"
elif [ "$NODE" == "slave1" ]; then
    SUFFIX="11"
    HOST_PORT="2221"
elif [ "$NODE" == "slave2" ]; then
    SUFFIX="12"
    HOST_PORT="2222"
else
    echo "âŒ é”™è¯¯: æœªçŸ¥èŠ‚ç‚¹å '$NODE'"
    exit 1
fi

echo "ğŸš€ æ­£åœ¨å¯åŠ¨èŠ‚ç‚¹: $NODE (SSH æ˜ å°„ç«¯å£: $HOST_PORT) ..."

qemu-system-aarch64 \
  -name "alpine_$NODE" \
  -M virt,accel=kvm \
  -cpu host \
  -m 2048 \
  -bios ./uefi.fd \
  -drive file=images/node_$NODE.qcow2,format=qcow2,if=virtio \
  -netdev user,id=net0,hostfwd=tcp::${HOST_PORT}-:22 \
  -device virtio-net-pci,netdev=net0 \
  -netdev socket,id=net1,mcast=230.0.0.1:1234 \
  -device virtio-net-pci,netdev=net1,mac=52:54:00:12:34:$SUFFIX \
  -device virtio-gpu-pci \
  -device qemu-xhci \
  -device usb-kbd \
  -device usb-tablet \
  -boot menu=on
```

 [chmod +x *]

./run_cluster master

## 2. è™šæ‹Ÿæœºï¼šé…ç½®å†…ç½‘ IP æ°¸ä¹…ç”Ÿæ•ˆ

åœ¨ **Alpine è™šæ‹Ÿæœºå†…éƒ¨**ä¿®æ”¹ç½‘ç»œé…ç½®æ–‡ä»¶ï¼Œç¡®ä¿é‡å¯å `192.168.1.x` ä»ç„¶å¯ç”¨ã€‚

### åœ¨ Master èŠ‚ç‚¹ä¸Šï¼š

ä¿®æ”¹ `/etc/network/interfaces`ï¼š

Plaintext

```
auto eth1
iface eth1 inet static
    address 192.168.1.10
    netmask 255.255.255.0
```

### åœ¨ Slave èŠ‚ç‚¹ä¸Šï¼š

åˆ†åˆ«ä¿®æ”¹ Slave1 (`.11`) å’Œ Slave2 (`.12`) çš„ `/etc/network/interfaces`ï¼š

Plaintext

```
# ä»¥ Slave1 ä¸ºä¾‹
auto eth1
iface eth1 inet static
    address 192.168.1.11
    netmask 255.255.255.0
```

**ç”Ÿæ•ˆå‘½ä»¤**ï¼šæ‰§è¡Œ `rc-service networking restart` æˆ– `reboot`ã€‚

## 3. å¯åŠ¨ Hadoop æœåŠ¡ (HDFS)

åœ¨ **Master èŠ‚ç‚¹**ä¸Šï¼Œé€šè¿‡å®ˆæŠ¤è¿›ç¨‹æ–¹å¼æ‰‹åŠ¨å¯åŠ¨ã€‚

Bash

```
# åŠ è½½ç¯å¢ƒå˜é‡
source /etc/profile

# å¯åŠ¨ NameNode å’Œ SecondaryNameNode
hdfs --daemon start namenode
hdfs --daemon start secondarynamenode

# è¿œç¨‹å¯åŠ¨ Slave èŠ‚ç‚¹çš„ DataNode
ssh slave1 "source /etc/profile; hdfs --daemon start datanode"
ssh slave2 "source /etc/profile; hdfs --daemon start datanode"

# æ£€æŸ¥ HDFS çŠ¶æ€
hdfs dfsadmin -report
```

## 4. å¯åŠ¨ YARN æœåŠ¡

åœ¨ **Master èŠ‚ç‚¹**ä¸Šå¯åŠ¨èµ„æºè°ƒåº¦ç³»ç»Ÿã€‚

Bash

```
# å¯åŠ¨ ResourceManager
yarn --daemon start resourcemanager

# è¿œç¨‹å¯åŠ¨ Slave èŠ‚ç‚¹çš„ NodeManager
ssh slave1 "source /etc/profile; yarn --daemon start nodemanager"
ssh slave2 "source /etc/profile; yarn --daemon start nodemanager"

# æ£€æŸ¥è¿›ç¨‹
jps
# åº”çœ‹åˆ°: NameNode, SecondaryNameNode, ResourceManager, Jps
```

## 5. éªŒè¯é›†ç¾¤çŠ¶æ€

åœ¨ **Master** ä¸ŠéªŒè¯å…¨çº¿è¿›ç¨‹æ˜¯å¦æ­£å¸¸ã€‚

- **Master èŠ‚ç‚¹åº”æœ‰**ï¼š`NameNode`, `SecondaryNameNode`, `ResourceManager`

- **Slave èŠ‚ç‚¹åº”æœ‰**ï¼š`DataNode`, `NodeManager`

- **æµ‹è¯• HDFS å†™å…¥**ï¼š

  Bash

  ```
  hdfs dfs -mkdir /success_test
  hdfs dfs -ls /
  ```

